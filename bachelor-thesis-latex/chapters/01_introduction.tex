% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}

A great progress in autonomous robotics was achieved in the last decades. The leading causes for this are ever-improving hardware, sensors price reduction and development of new, more efficient Artificial Neural Networks (ANN).
Usage of ANNs — computational systems based on biological neural circuits constituting a brain — becomes more widespread thanks to their ability to solve such complex problems as autonomous driving or facial recognition. Advancements in hardware and training methods enabled ANNs to process huge volumes of data much more efficiently than conventional algorithms. In cases when training data is not available, e.g. movement control, reinforcement learning can be used to train networks. In past few years ANNs have been trained to successfully manage robot control or play video games \cite{22}, \cite{23}, \cite{24}.
Still, training as well as executing complex neural networks consumes a lot of computational resources and can not always be done in real time. Problems such as autonomous vehicle driving are very resource-consuming — car sensors produce gigabytes of data every second which then require thousands of Watts to process. In comparison human brain consumes about 20W \cite{25}. One way to reduce energy cost and increase performance is by designing application-specific or ANN-specific hardware. 
Another way is developing of artificial neural networks that more closely imitate biological neural networks. Commonly used today Convolutional Neural Networks (CNN) differ significantly from biological neural circuit. One of the reasons is that biological brains do not process information discretely as CNNs do. Instead data is processed and transmitted in impulses also called spikes, asynchronously and in continuous time. 
Artificial neural networks based on this concept called Spiking Neural Networks \cite{26}. Spike generation in SNN is determined by differential equations representing multiple biological processes, such as membrane potential of a neuron cell. When a neuron potential reaches a certain threshold, it produces spike, and its potential resets. SNNs belong to a so called third generation of neural networks and while they promise improvements in terms of efficiency, they still are in active research phase \cite{27}. 
In this work, two different Reward-Modulated Spike-Time-Dependent-Plasticity learning schemes were implemented and used to train a snake-like robot navigating a wall-enclosed environment scenario. The environment was developed in Virtual Robot
Experimentation Platform (V-REP) simulator \cite{28}. Subsequently, the performance and ability to adapt to changing world of trained networks was verified.
